{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment football failed: No module named 'gfootball'\n"
     ]
    }
   ],
   "source": [
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.rule_based_agent import RuleBasedAgent\n",
    "from agents.greedy_agent import GreedyAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make(\"hungry_geese\", debug=True)\n",
    "config = env.configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_reward = 1\n",
    "winning_reward = 10\n",
    "losing_reward = -10\n",
    "discount = 0.85\n",
    "\n",
    "\n",
    "def discounted(discount_factor, nb_steps, step_reward):\n",
    "    discounted_reward = 0\n",
    "    for _ in range(int(nb_steps)):\n",
    "        discounted_reward = step_reward + discount_factor*discounted_reward\n",
    "    return discounted_reward\n",
    "\n",
    "step_200_reward = lambda my_goose, longuest_opponent: winning_reward if my_goose > longuest_opponent else 3*losing_reward\n",
    "win_game_reward = lambda step, my_goose, longuest_opponent: winning_reward + discounted(discount, 200-step, step_reward) #max((200-step), winning_reward)\n",
    "\n",
    "nb_opponents = 3\n",
    "\n",
    "steps_per_ep = 200\n",
    "num_episodes = 1000\n",
    "nb_files = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting iteration 0\n",
      "episode number:  0\n",
      "Body Hit: (0, <Action.EAST: 2>, 8, [7, 73, 62, 63, 74, 8, 19])\n",
      "episode number:  1\n",
      "Goose Collision: EAST\n",
      "Goose Collision: SOUTH\n",
      "Body Hit: (1, <Action.NORTH: 1>, 28, [39, 50, 61, 62, 51, 40, 29, 28, 27, 26, 37, 38, 49, 48, 59])\n",
      "episode number:  2\n",
      "Body Hit: (1, <Action.SOUTH: 3>, 62, [51, 52, 63, 62, 73, 74, 75])\n",
      "Body Hit: (3, <Action.SOUTH: 3>, 53, [42, 31, 32, 43, 54, 53, 52, 41])\n",
      "episode number:  3\n",
      "Body Hit: (3, <Action.WEST: 4>, 39, [40, 51, 50, 39, 28, 27, 26])\n",
      "Goose Collision: EAST\n",
      "episode number:  4\n",
      "Goose Collision: WEST\n",
      "Goose Collision: SOUTH\n",
      "episode number:  5\n",
      "Body Hit: (1, <Action.WEST: 4>, 24, [25, 26, 15, 14, 13, 24, 35, 36, 37])\n",
      "Body Hit: (2, <Action.SOUTH: 3>, 64, [53, 54, 65, 64, 63, 52, 51, 40])\n",
      "episode number:  6\n",
      "Goose Collision: EAST\n",
      "Goose Collision: EAST\n",
      "episode number:  7\n",
      "Body Hit: (3, <Action.SOUTH: 3>, 37, [26, 25, 36, 37, 48, 47])\n",
      "Goose Collision: NORTH\n",
      "episode number:  8\n",
      "Goose Collision: EAST\n",
      "episode number:  9\n",
      "Body Hit: (1, <Action.NORTH: 1>, 0, [11, 21, 10, 0, 66, 67, 68, 69, 58])\n",
      "Goose Collision: EAST\n"
     ]
    }
   ],
   "source": [
    "for it in range(nb_files):\n",
    "    print(f'starting iteration {it}')\n",
    "    name = f'it_{it}_v3.pkl'\n",
    "    episodes = []\n",
    "    for ep in range(num_episodes):\n",
    "        print('episode number: ', ep)\n",
    "        steps = []\n",
    "        my_agent = RuleBasedAgent()\n",
    "        agents =  [my_agent] + [(RuleBasedAgent() if np.random.rand()<1 else GreedyAgent()) for _ in range(nb_opponents)]\n",
    "        state_dict = env.reset(num_agents=nb_opponents + 1)[0]\n",
    "        observation = state_dict['observation']\n",
    "        my_goose_ind = observation['index']\n",
    "\n",
    "        reward = state_dict['reward']\n",
    "        action = state_dict['action']\n",
    "\n",
    "\n",
    "\n",
    "        done = False\n",
    "        for step in range(1, steps_per_ep):\n",
    "            actions = []\n",
    "\n",
    "            for i, agent in enumerate(agents):\n",
    "                obs = deepcopy(observation)\n",
    "                obs['index'] = i\n",
    "                action = agent(obs, config)\n",
    "                actions.append(action)\n",
    "\n",
    "            state_dict = env.step(actions)[0]\n",
    "            observation = state_dict['observation']\n",
    "            my_goose_ind = observation['index']\n",
    "\n",
    "            my_goose_length = len(observation['geese'][my_goose_ind])\n",
    "\n",
    "            longuest_opponent=0\n",
    "            for i, goose in enumerate(observation.geese):\n",
    "                if i != my_goose_ind:\n",
    "                    opponent_length = len(goose)\n",
    "                    if opponent_length > longuest_opponent:\n",
    "                        longuest_opponent = opponent_length\n",
    "\n",
    "            #new_state, _, _ = agent.getStateSpace(observation, config)\n",
    "\n",
    "            #reward = state_dict['reward']\n",
    "            action = state_dict['action']\n",
    "            status = state_dict['status']\n",
    "\n",
    "            if status != \"ACTIVE\":\n",
    "                done = True\n",
    "\n",
    "            # Check if my goose died\n",
    "            if my_goose_length == 0:\n",
    "                done = True\n",
    "                reward = losing_reward\n",
    "            elif (step+1) == steps_per_ep:\n",
    "                reward = step_200_reward(my_goose_length, longuest_opponent)\n",
    "                done = True\n",
    "            elif status != \"ACTIVE\":\n",
    "                reward = win_game_reward(step, my_goose_length, longuest_opponent)\n",
    "            else:\n",
    "                reward = step_reward\n",
    "\n",
    "            steps.append({'cur_state': my_agent.stateSpace,\n",
    "                                    'action': action,\n",
    "                                    'reward': reward,\n",
    "                                    'new_state': '',#new_state,\n",
    "                                    'status': status,\n",
    "                                    'done': done})\n",
    "            if done:\n",
    "#                 print('Done, Step: ', step+1)\n",
    "#                 print('status, ', status)\n",
    "                break\n",
    "\n",
    "            if step%50 == 0:\n",
    "                pass\n",
    "                #print(f'We survived {step+1} steps')\n",
    "        episodes.append(steps)\n",
    "    process(discount, episodes)\n",
    "    train_data = training_data(episodes)\n",
    "    with open(f'/home/charles/PycharmProjects/HungryGeese/data/{name}', 'wb') as f:\n",
    "        pickle.dump(train_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it_0_v2.pkl'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(not False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
