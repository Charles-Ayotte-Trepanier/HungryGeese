{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from agents.nnAgent import nnModel, train_test_splitter\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "policy_model = nnModel('policy')\n",
    "policy_model.build_model(3)\n",
    "\n",
    "v_model = nnModel('state_value')\n",
    "v_model.build_model(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_passes = 3\n",
    "nb_files = 22\n",
    "nb_epochs = 5\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(nb_passes):\n",
    "    print(f'Pass #{it}')\n",
    "    for i in range(nb_files):\n",
    "        path = f'./data/it_{i}_v2.pkl'\n",
    "        with open(path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        print(f'learning using \"{path}\"')\n",
    "        X = data['state']\n",
    "        y = data['y']\n",
    "        v = data['v']\n",
    "        X_train, X_test, y_train, y_test = train_test_splitter(X, y, 0.05)\n",
    "        \n",
    "        policy_model.fit(X_train,\n",
    "                         y_train,\n",
    "                         X_test,\n",
    "                         y_test,\n",
    "                         epoch=nb_epochs,\n",
    "                         batch_size=batch_size)\n",
    "        \n",
    "policy_model.save('rule_based_policy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nb_passes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-44a1a208ab23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_passes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Pass #{it}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'./data/it_{i}_v2.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nb_passes' is not defined"
     ]
    }
   ],
   "source": [
    "for it in range(nb_passes):\n",
    "    print(f'Pass #{it}')\n",
    "    for i in range(nb_files):\n",
    "        path = f'./data/it_{i}_v2.pkl'\n",
    "        with open(path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        print(f'learning using \"{path}\"')\n",
    "        X = data['state']\n",
    "        y = data['y']\n",
    "        v = data['v']\n",
    "        X_train, X_test, y_train, y_test, v_train, v_test = train_test_splitter(X, y, 0.05, v=v)\n",
    "\n",
    "        v_model.fit(X_train,\n",
    "                    v_train,\n",
    "                    X_test,\n",
    "                    v_test,\n",
    "                    epoch=nb_epochs,\n",
    "                    batch_size=batch_size)\n",
    "v_model.save('state_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.4375],\n",
       "        [-0.4375],\n",
       "        [-0.4375],\n",
       "        ...,\n",
       "        [-0.1875],\n",
       "        [-0.125 ],\n",
       "        [-0.125 ]]),\n",
       " array([[-0.4375],\n",
       "        [-0.4375],\n",
       "        [-0.375 ],\n",
       "        ...,\n",
       "        [ 0.125 ],\n",
       "        [ 0.125 ],\n",
       "        [ 0.125 ]]),\n",
       " array([[-1.  ],\n",
       "        [-0.95],\n",
       "        [-0.9 ],\n",
       "        ...,\n",
       "        [ 0.3 ],\n",
       "        [ 0.35],\n",
       "        [ 0.4 ]]),\n",
       " array([[-1.  ],\n",
       "        [-0.99],\n",
       "        [-0.98],\n",
       "        ...,\n",
       "        [-0.34],\n",
       "        [-0.33],\n",
       "        [-0.32]]),\n",
       " array([[ 0. ],\n",
       "        [ 0. ],\n",
       "        [-0.1],\n",
       "        ...,\n",
       "        [-0.5],\n",
       "        [-0.4],\n",
       "        [-0.4]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [5],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[15],\n",
       "        [ 3],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [15]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [ 5],\n",
       "        [ 0],\n",
       "        [13]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [12]]),\n",
       " array([[16],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [ 9],\n",
       "        [ 0],\n",
       "        [11]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [2],\n",
       "        [8],\n",
       "        [0]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [ 0],\n",
       "        [ 9],\n",
       "        [10]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [6],\n",
       "        [0],\n",
       "        [4]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [7],\n",
       "        [5],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [8],\n",
       "        [6],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [7],\n",
       "        [8]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [9]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[16],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [3],\n",
       "        [1],\n",
       "        [3]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [7],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [8],\n",
       "        [0],\n",
       "        [5]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [7],\n",
       "        [8],\n",
       "        [6]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [7],\n",
       "        [7]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [5],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [6],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [7],\n",
       "        [5],\n",
       "        [7]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [15],\n",
       "        [ 6],\n",
       "        [ 6]]),\n",
       " array([[16],\n",
       "        [ 4],\n",
       "        [ 2],\n",
       "        ...,\n",
       "        [ 4],\n",
       "        [ 1],\n",
       "        [ 3]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [15],\n",
       "        ...,\n",
       "        [ 6],\n",
       "        [ 9],\n",
       "        [ 7]]),\n",
       " array([[ 0],\n",
       "        [15],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [ 5],\n",
       "        [ 6],\n",
       "        [ 6]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [5],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [15],\n",
       "        ...,\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [10],\n",
       "        [ 0],\n",
       "        [ 5]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [11],\n",
       "        [ 9],\n",
       "        [ 9]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [ 0],\n",
       "        [10],\n",
       "        [ 8]]),\n",
       " array([[15],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 5]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [2],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [6],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [7],\n",
       "        [5],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [8],\n",
       "        [6],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [9],\n",
       "        [7],\n",
       "        [0]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [12],\n",
       "        [ 8],\n",
       "        [ 8]]),\n",
       " array([[ 0],\n",
       "        [ 3],\n",
       "        [ 2],\n",
       "        ...,\n",
       "        [ 0],\n",
       "        [11],\n",
       "        [ 9]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [ 0],\n",
       "        [15],\n",
       "        [15]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [3],\n",
       "        ...,\n",
       "        [5],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[ 0],\n",
       "        [15],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [15],\n",
       "        [ 0],\n",
       "        [ 0]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [ 0],\n",
       "        [15],\n",
       "        [ 5]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [6]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [13],\n",
       "        [13],\n",
       "        [ 7]]),\n",
       " array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        ...,\n",
       "        [ 0],\n",
       "        [12],\n",
       "        [10]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [3],\n",
       "        [3]]),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]),\n",
       " array([[16],\n",
       "        [ 0],\n",
       "        [ 4],\n",
       "        ...,\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0]])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.666666664089872,\n",
       " 6.666666663635144,\n",
       " 6.6666666631001705,\n",
       " 6.6666666624707895,\n",
       " 6.666666661730341,\n",
       " 6.666666660859225,\n",
       " 6.666666659834383,\n",
       " 6.666666658628686,\n",
       " 6.666666657210219,\n",
       " 6.666666655541434,\n",
       " 6.666666653578157,\n",
       " 6.66666665126842,\n",
       " 6.666666648551082,\n",
       " 6.666666645354215,\n",
       " 6.666666641593194,\n",
       " 6.666666637168464,\n",
       " 6.666666631962899,\n",
       " 6.666666625838705,\n",
       " 6.66666661863377,\n",
       " 6.666666610157377,\n",
       " 6.66666660018515,\n",
       " 6.6666665884531175,\n",
       " 6.666666574650727,\n",
       " 6.66666655841262,\n",
       " 6.666666539308966,\n",
       " 6.666666516834077,\n",
       " 6.666666490393032,\n",
       " 6.666666459285921,\n",
       " 6.666666422689318,\n",
       " 6.666666379634493,\n",
       " 6.666666328981757,\n",
       " 6.666666269390302,\n",
       " 6.666666199282709,\n",
       " 6.666666116803187,\n",
       " 6.6666660197684555,\n",
       " 6.666665905609948,\n",
       " 6.666665771305821,\n",
       " 6.666665613300966,\n",
       " 6.666665427412901,\n",
       " 6.66666520872106,\n",
       " 6.666664951436542,\n",
       " 6.666664648748873,\n",
       " 6.666664292645733,\n",
       " 6.666663873700863,\n",
       " 6.666663380824545,\n",
       " 6.6666628009700535,\n",
       " 6.666662118788298,\n",
       " 6.666661316221528,\n",
       " 6.666660372025326,\n",
       " 6.6666592612062665,\n",
       " 6.666657954360313,\n",
       " 6.666656416894487,\n",
       " 6.666654608111161,\n",
       " 6.666652480130778,\n",
       " 6.666649976624445,\n",
       " 6.666647031322876,\n",
       " 6.666643566262207,\n",
       " 6.666639489720244,\n",
       " 6.666634693788522,\n",
       " 6.666629051515908,\n",
       " 6.666622413548128,\n",
       " 6.666614604174268,\n",
       " 6.666605416675609,\n",
       " 6.666594607853658,\n",
       " 6.666581891592539,\n",
       " 6.666566931285341,\n",
       " 6.666549330923931,\n",
       " 6.666528624616389,\n",
       " 6.666504264254576,\n",
       " 6.666475605005384,\n",
       " 6.6664418882416285,\n",
       " 6.666402221460739,\n",
       " 6.6663555546596935,\n",
       " 6.666300652540817,\n",
       " 6.666236061812726,\n",
       " 6.666160072720855,\n",
       " 6.666070673789241,\n",
       " 6.665965498575578,\n",
       " 6.665841763030092,\n",
       " 6.665696191800108,\n",
       " 6.665524931529538,\n",
       " 6.665323448858281,\n",
       " 6.665086410421507,\n",
       " 6.664807541672362,\n",
       " 6.664479460791014,\n",
       " 6.664093483283546,\n",
       " 6.66363939209829,\n",
       " 6.663105167174459,\n",
       " 6.66247666726407,\n",
       " 6.661737255604788,\n",
       " 6.660867359535044,\n",
       " 6.65984395239417,\n",
       " 6.658639943993141,\n",
       " 6.657223463521343,\n",
       " 6.655557015907463,\n",
       " 6.653596489302897,\n",
       " 6.651289987415173,\n",
       " 6.648576455782557,\n",
       " 6.645384065626538,\n",
       " 6.641628312501809,\n",
       " 6.637209779413893,\n",
       " 6.632011505192815,\n",
       " 6.625895888462136,\n",
       " 6.618701045249572,\n",
       " 6.610236523823025,\n",
       " 6.600278263321206,\n",
       " 6.588562662730831,\n",
       " 6.574779603212742,\n",
       " 6.558564239073815,\n",
       " 6.539487340086841,\n",
       " 6.51704392951393,\n",
       " 6.490639917075212,\n",
       " 6.459576373029662,\n",
       " 6.42303102709372,\n",
       " 6.3800365024632,\n",
       " 6.329454708780236,\n",
       " 6.269946716212043,\n",
       " 6.199937313190639,\n",
       " 6.117573309636046,\n",
       " 6.02067448192476,\n",
       " 5.906675861087953,\n",
       " 5.772559836574063,\n",
       " 5.614776278322427,\n",
       " 5.4291485627322675,\n",
       " 5.210763014979138,\n",
       " 4.953838841151927,\n",
       " 4.651575107237561,\n",
       " 4.295970714397131,\n",
       " 3.8776126051730957,\n",
       " 3.385426594321289,\n",
       " 2.806384228613281,\n",
       " 2.125157916015625,\n",
       " 1.3237151953125001,\n",
       " 0.3808414062500002,\n",
       " -0.7284218749999998,\n",
       " -2.0334375,\n",
       " -3.5687499999999996,\n",
       " -5.375,\n",
       " -7.5,\n",
       " -10.0,\n",
       " 6.666666666665205,\n",
       " 6.6666666666649474,\n",
       " 6.666666666664645,\n",
       " 6.666666666664288,\n",
       " 6.666666666663869,\n",
       " 6.666666666663375,\n",
       " 6.6666666666627945,\n",
       " 6.6666666666621115,\n",
       " 6.666666666661308,\n",
       " 6.666666666660362,\n",
       " 6.66666666665925,\n",
       " 6.666666666657941,\n",
       " 6.666666666656401,\n",
       " 6.66666666665459,\n",
       " 6.66666666665246,\n",
       " 6.666666666649952,\n",
       " 6.666666666647003,\n",
       " 6.666666666643533,\n",
       " 6.6666666666394505,\n",
       " 6.666666666634648,\n",
       " 6.6666666666289975,\n",
       " 6.66666666662235,\n",
       " 6.66666666661453,\n",
       " 6.666666666605329,\n",
       " 6.666666666594505,\n",
       " 6.666666666581771,\n",
       " 6.66666666656679,\n",
       " 6.666666666549165,\n",
       " 6.66666666652843,\n",
       " 6.666666666504035,\n",
       " 6.666666666475336,\n",
       " 6.6666666664415715,\n",
       " 6.6666666664018495,\n",
       " 6.666666666355117,\n",
       " 6.666666666300138,\n",
       " 6.666666666235456,\n",
       " 6.666666666159361,\n",
       " 6.666666666069837,\n",
       " 6.666666665964514,\n",
       " 6.666666665840605,\n",
       " 6.666666665694829,\n",
       " 6.666666665523329,\n",
       " 6.666666665321563,\n",
       " 6.666666665084192,\n",
       " 6.666666664804932,\n",
       " 6.6666666644763914,\n",
       " 6.666666664089872,\n",
       " 6.666666663635144,\n",
       " 6.6666666631001705,\n",
       " 6.6666666624707895,\n",
       " 6.666666661730341,\n",
       " 6.666666660859225,\n",
       " 6.666666659834383,\n",
       " 6.666666658628686,\n",
       " 6.666666657210219,\n",
       " 6.666666655541434,\n",
       " 6.666666653578157,\n",
       " 6.66666665126842,\n",
       " 6.666666648551082,\n",
       " 6.666666645354215,\n",
       " 6.666666641593194,\n",
       " 6.666666637168464,\n",
       " 6.666666631962899,\n",
       " 6.666666625838705,\n",
       " 6.66666661863377,\n",
       " 6.666666610157377,\n",
       " 6.66666660018515,\n",
       " 6.6666665884531175,\n",
       " 6.666666574650727,\n",
       " 6.66666655841262,\n",
       " 6.666666539308966,\n",
       " 6.666666516834077,\n",
       " 6.666666490393032,\n",
       " 6.666666459285921,\n",
       " 6.666666422689318,\n",
       " 6.666666379634493,\n",
       " 6.666666328981757,\n",
       " 6.666666269390302,\n",
       " 6.666666199282709,\n",
       " 6.666666116803187,\n",
       " 6.6666660197684555,\n",
       " 6.666665905609948,\n",
       " 6.666665771305821,\n",
       " 6.666665613300966,\n",
       " 6.666665427412901,\n",
       " 6.66666520872106,\n",
       " 6.666664951436542,\n",
       " 6.666664648748873,\n",
       " 6.666664292645733,\n",
       " 6.666663873700863,\n",
       " 6.666663380824545,\n",
       " 6.6666628009700535,\n",
       " 6.666662118788298,\n",
       " 6.666661316221528,\n",
       " 6.666660372025326,\n",
       " 6.6666592612062665,\n",
       " 6.666657954360313,\n",
       " 6.666656416894487,\n",
       " 6.666654608111161,\n",
       " 6.666652480130778,\n",
       " 6.666649976624445,\n",
       " 6.666647031322876,\n",
       " 6.666643566262207,\n",
       " 6.666639489720244,\n",
       " 6.666634693788522,\n",
       " 6.666629051515908,\n",
       " 6.666622413548128,\n",
       " 6.666614604174268,\n",
       " 6.666605416675609,\n",
       " 6.666594607853658,\n",
       " 6.666581891592539,\n",
       " 6.666566931285341,\n",
       " 6.666549330923931,\n",
       " 6.666528624616389,\n",
       " 6.666504264254576,\n",
       " 6.666475605005384,\n",
       " 6.6664418882416285,\n",
       " 6.666402221460739,\n",
       " 6.6663555546596935,\n",
       " 6.666300652540817,\n",
       " 6.666236061812726,\n",
       " 6.666160072720855,\n",
       " 6.666070673789241,\n",
       " 6.665965498575578,\n",
       " 6.665841763030092,\n",
       " 6.665696191800108,\n",
       " 6.665524931529538,\n",
       " 6.665323448858281,\n",
       " 6.665086410421507,\n",
       " 6.664807541672362,\n",
       " 6.664479460791014,\n",
       " 6.664093483283546,\n",
       " 6.66363939209829,\n",
       " 6.663105167174459,\n",
       " 6.66247666726407,\n",
       " 6.661737255604788,\n",
       " 6.660867359535044,\n",
       " 6.65984395239417,\n",
       " 6.658639943993141,\n",
       " 6.657223463521343,\n",
       " 6.655557015907463,\n",
       " 6.653596489302897,\n",
       " 6.651289987415173,\n",
       " 6.648576455782557,\n",
       " 6.645384065626538,\n",
       " 6.641628312501809,\n",
       " 6.637209779413893,\n",
       " 6.632011505192815,\n",
       " 6.625895888462136,\n",
       " 6.618701045249572,\n",
       " 6.610236523823025,\n",
       " 6.600278263321206,\n",
       " 6.588562662730831,\n",
       " 6.574779603212742,\n",
       " 6.558564239073815,\n",
       " 6.539487340086841,\n",
       " 6.51704392951393,\n",
       " 6.490639917075212,\n",
       " 6.459576373029662,\n",
       " 6.42303102709372,\n",
       " 6.3800365024632,\n",
       " 6.329454708780236,\n",
       " 6.269946716212043,\n",
       " 6.199937313190639,\n",
       " 6.117573309636046,\n",
       " 6.02067448192476,\n",
       " 5.906675861087953,\n",
       " 5.772559836574063,\n",
       " 5.614776278322427,\n",
       " 5.4291485627322675,\n",
       " 5.210763014979138,\n",
       " 4.953838841151927,\n",
       " 4.651575107237561,\n",
       " 4.295970714397131,\n",
       " 3.8776126051730957,\n",
       " 3.385426594321289,\n",
       " 2.806384228613281,\n",
       " 2.125157916015625,\n",
       " 1.3237151953125001,\n",
       " 0.3808414062500002,\n",
       " -0.7284218749999998,\n",
       " -2.0334375,\n",
       " -3.5687499999999996,\n",
       " -5.375,\n",
       " -7.5,\n",
       " -10.0,\n",
       " 6.666594607853658,\n",
       " 6.666581891592539,\n",
       " 6.666566931285341,\n",
       " 6.666549330923931,\n",
       " 6.666528624616389,\n",
       " 6.666504264254576,\n",
       " 6.666475605005384,\n",
       " 6.6664418882416285,\n",
       " 6.666402221460739,\n",
       " 6.6663555546596935,\n",
       " 6.666300652540817,\n",
       " 6.666236061812726,\n",
       " 6.666160072720855,\n",
       " 6.666070673789241,\n",
       " 6.665965498575578,\n",
       " 6.665841763030092,\n",
       " 6.665696191800108,\n",
       " 6.665524931529538,\n",
       " 6.665323448858281,\n",
       " 6.665086410421507,\n",
       " 6.664807541672362,\n",
       " 6.664479460791014,\n",
       " 6.664093483283546,\n",
       " 6.66363939209829,\n",
       " 6.663105167174459,\n",
       " 6.66247666726407,\n",
       " 6.661737255604788,\n",
       " 6.660867359535044,\n",
       " 6.65984395239417,\n",
       " 6.658639943993141,\n",
       " 6.657223463521343,\n",
       " 6.655557015907463,\n",
       " 6.653596489302897,\n",
       " 6.651289987415173,\n",
       " 6.648576455782557,\n",
       " 6.645384065626538,\n",
       " 6.641628312501809,\n",
       " 6.637209779413893,\n",
       " 6.632011505192815,\n",
       " 6.625895888462136,\n",
       " 6.618701045249572,\n",
       " 6.610236523823025,\n",
       " 6.600278263321206,\n",
       " 6.588562662730831,\n",
       " 6.574779603212742,\n",
       " 6.558564239073815,\n",
       " 6.539487340086841,\n",
       " 6.51704392951393,\n",
       " 6.490639917075212,\n",
       " 6.459576373029662,\n",
       " 6.42303102709372,\n",
       " 6.3800365024632,\n",
       " 6.329454708780236,\n",
       " 6.269946716212043,\n",
       " 6.199937313190639,\n",
       " 6.117573309636046,\n",
       " 6.02067448192476,\n",
       " 5.906675861087953,\n",
       " 5.772559836574063,\n",
       " 5.614776278322427,\n",
       " 5.4291485627322675,\n",
       " 5.210763014979138,\n",
       " 4.953838841151927,\n",
       " 4.651575107237561,\n",
       " 4.295970714397131,\n",
       " 3.8776126051730957,\n",
       " 3.385426594321289,\n",
       " 2.806384228613281,\n",
       " 2.125157916015625,\n",
       " 1.3237151953125001,\n",
       " 0.3808414062500002,\n",
       " -0.7284218749999998,\n",
       " -2.0334375,\n",
       " -3.5687499999999996,\n",
       " -5.375,\n",
       " -7.5,\n",
       " -10.0,\n",
       " 6.666666666666278,\n",
       " 6.6666666666662096,\n",
       " 6.666666666666129,\n",
       " 6.666666666666034,\n",
       " 6.666666666665922,\n",
       " 6.66666666666579,\n",
       " 6.666666666665636,\n",
       " 6.666666666665454,\n",
       " 6.66666666666524,\n",
       " 6.666666666664988,\n",
       " 6.6666666666646925,\n",
       " 6.666666666664344,\n",
       " 6.666666666663935,\n",
       " 6.6666666666634535,\n",
       " 6.666666666662887,\n",
       " 6.66666666666222,\n",
       " 6.666666666661436,\n",
       " 6.666666666660513,\n",
       " 6.6666666666594265,\n",
       " 6.666666666658149,\n",
       " 6.6666666666566465,\n",
       " 6.666666666654878,\n",
       " 6.666666666652798,\n",
       " 6.666666666650351,\n",
       " 6.6666666666474725,\n",
       " 6.666666666644085,\n",
       " 6.6666666666401,\n",
       " 6.666666666635412,\n",
       " 6.666666666629896,\n",
       " 6.666666666623407,\n",
       " 6.6666666666157735,\n",
       " 6.666666666606792,\n",
       " 6.666666666596226,\n",
       " 6.666666666583796,\n",
       " 6.6666666665691725,\n",
       " 6.666666666551968,\n",
       " 6.666666666531727,\n",
       " 6.666666666507914,\n",
       " 6.666666666479899,\n",
       " 6.6666666664469405,\n",
       " 6.666666666408165,\n",
       " 6.666666666362548,\n",
       " 6.666666666308879,\n",
       " 6.666666666245741,\n",
       " 6.6666666661714595,\n",
       " 6.66666666608407,\n",
       " 6.666666665981259,\n",
       " 6.666666665860305,\n",
       " 6.666666665718006,\n",
       " 6.666666665550595,\n",
       " 6.666666665353642,\n",
       " 6.666666665121932,\n",
       " 6.666666664849332,\n",
       " 6.666666664528626,\n",
       " 6.666666664151325,\n",
       " 6.666666663707442,\n",
       " 6.666666663185226,\n",
       " 6.666666662570854,\n",
       " 6.666666661848064,\n",
       " 6.666666660997722,\n",
       " 6.66666665999732,\n",
       " 6.666666658820377,\n",
       " 6.666666657435738,\n",
       " 6.66666665580675,\n",
       " 6.666666653890295,\n",
       " 6.666666651635642,\n",
       " 6.666666648983108,\n",
       " 6.666666645862481,\n",
       " 6.666666642191155,\n",
       " 6.666666637871947,\n",
       " 6.666666632790525,\n",
       " 6.666666626812383,\n",
       " 6.666666619779273,\n",
       " 6.666666611505028,\n",
       " 6.666666601770622,\n",
       " 6.666666590318379,\n",
       " 6.666666576845152,\n",
       " 6.666666560994297,\n",
       " 6.666666542346232,\n",
       " 6.666666520407332,\n",
       " 6.666666494596861,\n",
       " 6.666666464231601,\n",
       " 6.666666428507766,\n",
       " 6.666666386479726,\n",
       " 6.666666337034972,\n",
       " 6.666666278864673,\n",
       " 6.666666210429027,\n",
       " 6.666666129916503,\n",
       " 6.6666660351958855,\n",
       " 6.666665923759866,\n",
       " 6.666665792658666,\n",
       " 6.66666563842196,\n",
       " 6.666665456967012,\n",
       " 6.666665243490602,\n",
       " 6.666664992341885,\n",
       " 6.6666646968728065,\n",
       " 6.666664349262126,\n",
       " 6.666663940308384,\n",
       " 6.666663459186334,\n",
       " 6.666662893160393,\n",
       " 6.666662227247522,\n",
       " 6.666661443820614,\n",
       " 6.6666605221419,\n",
       " 6.666659437814,\n",
       " 6.666658162134118,\n",
       " 6.666656661334256,\n",
       " 6.66665489568736,\n",
       " 6.666652818455718,\n",
       " 6.666650374653787,\n",
       " 6.666647499592691,\n",
       " 6.666644117167872,\n",
       " 6.666640137844555,\n",
       " 6.666635456287712,\n",
       " 6.666629948573779,\n",
       " 6.666623468910329,\n",
       " 6.666615845776858,\n",
       " 6.666606877384538,\n",
       " 6.6665963263347505,\n",
       " 6.666583913335001,\n",
       " 6.666569309805883,\n",
       " 6.666552129183392,\n",
       " 6.666531916686344,\n",
       " 6.6665081372780515,\n",
       " 6.66648016150359,\n",
       " 6.666447248827753,\n",
       " 6.66640852803265,\n",
       " 6.666362974156059,\n",
       " 6.66630938136007,\n",
       " 6.666246331011847,\n",
       " 6.666172154131585,\n",
       " 6.66608488721363,\n",
       " 6.66598222025133,\n",
       " 6.665861435589799,\n",
       " 6.665719335987999,\n",
       " 6.665552159985881,\n",
       " 6.665355482336332,\n",
       " 6.665124096866273,\n",
       " 6.664851878666203,\n",
       " 6.664531621960239,\n",
       " 6.664154849364987,\n",
       " 6.66371158748822,\n",
       " 6.6631901029273175,\n",
       " 6.662576591679198,\n",
       " 6.6618548137402325,\n",
       " 6.661005663223803,\n",
       " 6.660006662616239,\n",
       " 6.658831367783811,\n",
       " 6.657448667980954,\n",
       " 6.655821962330534,\n",
       " 6.6539081909770985,\n",
       " 6.6516566952671745,\n",
       " 6.6490078767849115,\n",
       " 6.645891619746955,\n",
       " 6.642225434996417,\n",
       " 6.637912276466373,\n",
       " 6.63283797231338,\n",
       " 6.626868202721624,\n",
       " 6.619844944378382,\n",
       " 6.611582287503979,\n",
       " 6.601861514710564,\n",
       " 6.590425311424194,\n",
       " 6.576970954616699,\n",
       " 6.561142299549058,\n",
       " 6.542520352410657,\n",
       " 6.520612179306655,\n",
       " 6.49483785800783,\n",
       " 6.464515127068035,\n",
       " 6.428841325962394,\n",
       " 6.386872148191052,\n",
       " 6.337496644930649,\n",
       " 6.2794078175654695,\n",
       " 6.211068020665258,\n",
       " 6.130668259606186,\n",
       " 6.036080305419043,\n",
       " 5.924800359316522,\n",
       " 5.793882775666496,\n",
       " 5.639862089019408,\n",
       " 5.458661281199303,\n",
       " 5.245483860234474,\n",
       " 4.9946868943934986,\n",
       " 4.69963164046294,\n",
       " 4.352507812309341,\n",
       " 3.944126838010989,\n",
       " 3.4636786329541045,\n",
       " 2.8984454505342407,\n",
       " 2.2334652359226363,\n",
       " 1.4511355716736898,\n",
       " 0.5307477313808114,\n",
       " -0.552061492493163,\n",
       " -1.82595469705078,\n",
       " -3.324652584765624,\n",
       " -5.087826570312499,\n",
       " -7.16214890625,\n",
       " -9.602528125,\n",
       " -12.4735625,\n",
       " -15.85125,\n",
       " -19.825,\n",
       " -24.5,\n",
       " -30.0,\n",
       " 6.666665905609948,\n",
       " 6.666665771305821,\n",
       " 6.666665613300966,\n",
       " 6.666665427412901,\n",
       " 6.66666520872106,\n",
       " 6.666664951436542,\n",
       " 6.666664648748873,\n",
       " 6.666664292645733,\n",
       " 6.666663873700863,\n",
       " 6.666663380824545,\n",
       " 6.6666628009700535,\n",
       " 6.666662118788298,\n",
       " 6.666661316221528,\n",
       " 6.666660372025326,\n",
       " 6.6666592612062665,\n",
       " 6.666657954360313,\n",
       " 6.666656416894487,\n",
       " 6.666654608111161,\n",
       " 6.666652480130778,\n",
       " 6.666649976624445,\n",
       " 6.666647031322876,\n",
       " 6.666643566262207,\n",
       " 6.666639489720244,\n",
       " 6.666634693788522,\n",
       " 6.666629051515908,\n",
       " 6.666622413548128,\n",
       " 6.666614604174268,\n",
       " 6.666605416675609,\n",
       " 6.666594607853658,\n",
       " 6.666581891592539,\n",
       " 6.666566931285341,\n",
       " 6.666549330923931,\n",
       " 6.666528624616389,\n",
       " 6.666504264254576,\n",
       " 6.666475605005384,\n",
       " 6.6664418882416285,\n",
       " 6.666402221460739,\n",
       " 6.6663555546596935,\n",
       " 6.666300652540817,\n",
       " 6.666236061812726,\n",
       " 6.666160072720855,\n",
       " 6.666070673789241,\n",
       " 6.665965498575578,\n",
       " 6.665841763030092,\n",
       " 6.665696191800108,\n",
       " 6.665524931529538,\n",
       " 6.665323448858281,\n",
       " 6.665086410421507,\n",
       " 6.664807541672362,\n",
       " 6.664479460791014,\n",
       " 6.664093483283546,\n",
       " 6.66363939209829,\n",
       " 6.663105167174459,\n",
       " 6.66247666726407,\n",
       " 6.661737255604788,\n",
       " 6.660867359535044,\n",
       " 6.65984395239417,\n",
       " 6.658639943993141,\n",
       " 6.657223463521343,\n",
       " 6.655557015907463,\n",
       " 6.653596489302897,\n",
       " 6.651289987415173,\n",
       " 6.648576455782557,\n",
       " 6.645384065626538,\n",
       " 6.641628312501809,\n",
       " 6.637209779413893,\n",
       " 6.632011505192815,\n",
       " 6.625895888462136,\n",
       " 6.618701045249572,\n",
       " 6.610236523823025,\n",
       " 6.600278263321206,\n",
       " 6.588562662730831,\n",
       " 6.574779603212742,\n",
       " 6.558564239073815,\n",
       " 6.539487340086841,\n",
       " 6.51704392951393,\n",
       " 6.490639917075212,\n",
       " 6.459576373029662,\n",
       " 6.42303102709372,\n",
       " 6.3800365024632,\n",
       " 6.329454708780236,\n",
       " 6.269946716212043,\n",
       " 6.199937313190639,\n",
       " 6.117573309636046,\n",
       " 6.02067448192476,\n",
       " 5.906675861087953,\n",
       " 5.772559836574063,\n",
       " 5.614776278322427,\n",
       " 5.4291485627322675,\n",
       " 5.210763014979138,\n",
       " 4.953838841151927,\n",
       " 4.651575107237561,\n",
       " 4.295970714397131,\n",
       " 3.8776126051730957,\n",
       " 3.385426594321289,\n",
       " 2.806384228613281,\n",
       " 2.125157916015625,\n",
       " 1.3237151953125001,\n",
       " 0.3808414062500002,\n",
       " -0.7284218749999998,\n",
       " -2.0334375,\n",
       " -3.5687499999999996,\n",
       " -5.375,\n",
       " -7.5,\n",
       " -10.0,\n",
       " 6.666666666649952,\n",
       " 6.666666666647003,\n",
       " 6.666666666643533,\n",
       " 6.6666666666394505,\n",
       " 6.666666666634648,\n",
       " 6.6666666666289975,\n",
       " 6.66666666662235,\n",
       " 6.66666666661453,\n",
       " 6.666666666605329,\n",
       " 6.666666666594505,\n",
       " 6.666666666581771,\n",
       " 6.66666666656679,\n",
       " 6.666666666549165,\n",
       " 6.66666666652843,\n",
       " 6.666666666504035,\n",
       " 6.666666666475336,\n",
       " 6.6666666664415715,\n",
       " 6.6666666664018495,\n",
       " 6.666666666355117,\n",
       " 6.666666666300138,\n",
       " 6.666666666235456,\n",
       " 6.666666666159361,\n",
       " 6.666666666069837,\n",
       " 6.666666665964514,\n",
       " 6.666666665840605,\n",
       " 6.666666665694829,\n",
       " 6.666666665523329,\n",
       " 6.666666665321563,\n",
       " 6.666666665084192,\n",
       " 6.666666664804932,\n",
       " 6.6666666644763914,\n",
       " 6.666666664089872,\n",
       " 6.666666663635144,\n",
       " 6.6666666631001705,\n",
       " 6.6666666624707895,\n",
       " 6.666666661730341,\n",
       " 6.666666660859225,\n",
       " 6.666666659834383,\n",
       " 6.666666658628686,\n",
       " 6.666666657210219,\n",
       " 6.666666655541434,\n",
       " 6.666666653578157,\n",
       " 6.66666665126842,\n",
       " 6.666666648551082,\n",
       " 6.666666645354215,\n",
       " 6.666666641593194,\n",
       " 6.666666637168464,\n",
       " 6.666666631962899,\n",
       " 6.666666625838705,\n",
       " 6.66666661863377,\n",
       " 6.666666610157377,\n",
       " 6.66666660018515,\n",
       " 6.6666665884531175,\n",
       " 6.666666574650727,\n",
       " 6.66666655841262,\n",
       " 6.666666539308966,\n",
       " 6.666666516834077,\n",
       " 6.666666490393032,\n",
       " 6.666666459285921,\n",
       " 6.666666422689318,\n",
       " 6.666666379634493,\n",
       " 6.666666328981757,\n",
       " 6.666666269390302,\n",
       " 6.666666199282709,\n",
       " 6.666666116803187,\n",
       " 6.6666660197684555,\n",
       " 6.666665905609948,\n",
       " 6.666665771305821,\n",
       " 6.666665613300966,\n",
       " 6.666665427412901,\n",
       " 6.66666520872106,\n",
       " 6.666664951436542,\n",
       " 6.666664648748873,\n",
       " 6.666664292645733,\n",
       " 6.666663873700863,\n",
       " 6.666663380824545,\n",
       " 6.6666628009700535,\n",
       " 6.666662118788298,\n",
       " 6.666661316221528,\n",
       " 6.666660372025326,\n",
       " 6.6666592612062665,\n",
       " 6.666657954360313,\n",
       " 6.666656416894487,\n",
       " 6.666654608111161,\n",
       " 6.666652480130778,\n",
       " 6.666649976624445,\n",
       " 6.666647031322876,\n",
       " 6.666643566262207,\n",
       " 6.666639489720244,\n",
       " 6.666634693788522,\n",
       " 6.666629051515908,\n",
       " 6.666622413548128,\n",
       " 6.666614604174268,\n",
       " 6.666605416675609,\n",
       " 6.666594607853658,\n",
       " 6.666581891592539,\n",
       " 6.666566931285341,\n",
       " 6.666549330923931,\n",
       " 6.666528624616389,\n",
       " 6.666504264254576,\n",
       " 6.666475605005384,\n",
       " 6.6664418882416285,\n",
       " 6.666402221460739,\n",
       " 6.6663555546596935,\n",
       " 6.666300652540817,\n",
       " 6.666236061812726,\n",
       " 6.666160072720855,\n",
       " 6.666070673789241,\n",
       " 6.665965498575578,\n",
       " 6.665841763030092,\n",
       " 6.665696191800108,\n",
       " 6.665524931529538,\n",
       " 6.665323448858281,\n",
       " 6.665086410421507,\n",
       " 6.664807541672362,\n",
       " 6.664479460791014,\n",
       " 6.664093483283546,\n",
       " 6.66363939209829,\n",
       " 6.663105167174459,\n",
       " 6.66247666726407,\n",
       " 6.661737255604788,\n",
       " 6.660867359535044,\n",
       " 6.65984395239417,\n",
       " 6.658639943993141,\n",
       " 6.657223463521343,\n",
       " 6.655557015907463,\n",
       " 6.653596489302897,\n",
       " 6.651289987415173,\n",
       " 6.648576455782557,\n",
       " 6.645384065626538,\n",
       " 6.641628312501809,\n",
       " 6.637209779413893,\n",
       " 6.632011505192815,\n",
       " 6.625895888462136,\n",
       " 6.618701045249572,\n",
       " 6.610236523823025,\n",
       " 6.600278263321206,\n",
       " 6.588562662730831,\n",
       " 6.574779603212742,\n",
       " 6.558564239073815,\n",
       " 6.539487340086841,\n",
       " 6.51704392951393,\n",
       " 6.490639917075212,\n",
       " 6.459576373029662,\n",
       " 6.42303102709372,\n",
       " 6.3800365024632,\n",
       " 6.329454708780236,\n",
       " 6.269946716212043,\n",
       " 6.199937313190639,\n",
       " 6.117573309636046,\n",
       " 6.02067448192476,\n",
       " 5.906675861087953,\n",
       " 5.772559836574063,\n",
       " 5.614776278322427,\n",
       " 5.4291485627322675,\n",
       " 5.210763014979138,\n",
       " 4.953838841151927,\n",
       " 4.651575107237561,\n",
       " 4.295970714397131,\n",
       " 3.8776126051730957,\n",
       " 3.385426594321289,\n",
       " 2.806384228613281,\n",
       " 2.125157916015625,\n",
       " 1.3237151953125001,\n",
       " 0.3808414062500002,\n",
       " -0.7284218749999998,\n",
       " -2.0334375,\n",
       " -3.5687499999999996,\n",
       " -5.375,\n",
       " -7.5,\n",
       " -10.0,\n",
       " 6.666666666666197,\n",
       " 6.6666666666661145,\n",
       " 6.666666666666018,\n",
       " 6.666666666665903,\n",
       " 6.666666666665769,\n",
       " 6.666666666665611,\n",
       " 6.666666666665424,\n",
       " 6.666666666665205,\n",
       " 6.6666666666649474,\n",
       " 6.666666666664645,\n",
       " 6.666666666664288,\n",
       " 6.666666666663869,\n",
       " 6.666666666663375,\n",
       " 6.6666666666627945,\n",
       " 6.6666666666621115,\n",
       " 6.666666666661308,\n",
       " 6.666666666660362,\n",
       " 6.66666666665925,\n",
       " 6.666666666657941,\n",
       " 6.666666666656401,\n",
       " 6.66666666665459,\n",
       " 6.66666666665246,\n",
       " 6.666666666649952,\n",
       " 6.666666666647003,\n",
       " 6.666666666643533,\n",
       " 6.6666666666394505,\n",
       " 6.666666666634648,\n",
       " 6.6666666666289975,\n",
       " 6.66666666662235,\n",
       " 6.66666666661453,\n",
       " 6.666666666605329,\n",
       " 6.666666666594505,\n",
       " 6.666666666581771,\n",
       " 6.66666666656679,\n",
       " 6.666666666549165,\n",
       " 6.66666666652843,\n",
       " 6.666666666504035,\n",
       " 6.666666666475336,\n",
       " 6.6666666664415715,\n",
       " 6.6666666664018495,\n",
       " 6.666666666355117,\n",
       " 6.666666666300138,\n",
       " 6.666666666235456,\n",
       " 6.666666666159361,\n",
       " 6.666666666069837,\n",
       " 6.666666665964514,\n",
       " 6.666666665840605,\n",
       " 6.666666665694829,\n",
       " 6.666666665523329,\n",
       " 6.666666665321563,\n",
       " 6.666666665084192,\n",
       " 6.666666664804932,\n",
       " 6.6666666644763914,\n",
       " 6.666666664089872,\n",
       " 6.666666663635144,\n",
       " 6.6666666631001705,\n",
       " 6.6666666624707895,\n",
       " 6.666666661730341,\n",
       " 6.666666660859225,\n",
       " 6.666666659834383,\n",
       " 6.666666658628686,\n",
       " 6.666666657210219,\n",
       " 6.666666655541434,\n",
       " 6.666666653578157,\n",
       " 6.66666665126842,\n",
       " 6.666666648551082,\n",
       " 6.666666645354215,\n",
       " 6.666666641593194,\n",
       " 6.666666637168464,\n",
       " 6.666666631962899,\n",
       " 6.666666625838705,\n",
       " 6.66666661863377,\n",
       " 6.666666610157377,\n",
       " 6.66666660018515,\n",
       " 6.6666665884531175,\n",
       " 6.666666574650727,\n",
       " 6.66666655841262,\n",
       " 6.666666539308966,\n",
       " 6.666666516834077,\n",
       " 6.666666490393032,\n",
       " 6.666666459285921,\n",
       " 6.666666422689318,\n",
       " 6.666666379634493,\n",
       " 6.666666328981757,\n",
       " 6.666666269390302,\n",
       " 6.666666199282709,\n",
       " 6.666666116803187,\n",
       " 6.6666660197684555,\n",
       " 6.666665905609948,\n",
       " 6.666665771305821,\n",
       " 6.666665613300966,\n",
       " 6.666665427412901,\n",
       " 6.66666520872106,\n",
       " 6.666664951436542,\n",
       " 6.666664648748873,\n",
       " 6.666664292645733,\n",
       " 6.666663873700863,\n",
       " 6.666663380824545,\n",
       " 6.6666628009700535,\n",
       " 6.666662118788298,\n",
       " 6.666661316221528,\n",
       " 6.666660372025326,\n",
       " 6.6666592612062665,\n",
       " 6.666657954360313,\n",
       " 6.666656416894487,\n",
       " 6.666654608111161,\n",
       " 6.666652480130778,\n",
       " 6.666649976624445,\n",
       " 6.666647031322876,\n",
       " 6.666643566262207,\n",
       " 6.666639489720244,\n",
       " 6.666634693788522,\n",
       " 6.666629051515908,\n",
       " 6.666622413548128,\n",
       " 6.666614604174268,\n",
       " 6.666605416675609,\n",
       " 6.666594607853658,\n",
       " 6.666581891592539,\n",
       " 6.666566931285341,\n",
       " 6.666549330923931,\n",
       " 6.666528624616389,\n",
       " 6.666504264254576,\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_advantage(X, model):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from agents.nnAgent import nnModel, train_test_splitter\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce_model = nnModel('actor_critic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'./data/it_0_v2.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['state']\n",
    "y = data['y']\n",
    "v = data['v']\n",
    "X_train, X_test, y_train, y_test, v_train, v_test = train_test_splitter(X, y, 0.05, v=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinforce_model.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = X_test + [v_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train + [v_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2707125 , 0.2513453 , 0.22590981, 0.2520324 ],\n",
       "       [0.19331466, 0.22725874, 0.31421083, 0.26521572],\n",
       "       [0.24475338, 0.2635193 , 0.25421354, 0.23751374],\n",
       "       [0.2590985 , 0.24802794, 0.23698923, 0.25588438],\n",
       "       [0.20159769, 0.23186167, 0.30598143, 0.2605593 ],\n",
       "       [0.23178771, 0.2537843 , 0.2683345 , 0.24609353],\n",
       "       [0.24947914, 0.24418765, 0.26008546, 0.24624771],\n",
       "       [0.22400893, 0.24987115, 0.27230942, 0.25381052],\n",
       "       [0.24556835, 0.2650649 , 0.25942785, 0.22993891],\n",
       "       [0.27468607, 0.27917215, 0.22837645, 0.21776542],\n",
       "       [0.23816544, 0.23292162, 0.2681064 , 0.26080653],\n",
       "       [0.26135236, 0.2509886 , 0.24235629, 0.24530281],\n",
       "       [0.22897157, 0.23685037, 0.2702013 , 0.2639767 ],\n",
       "       [0.2311213 , 0.26255873, 0.27154806, 0.234772  ],\n",
       "       [0.27146247, 0.23608547, 0.22622305, 0.26622903],\n",
       "       [0.24874417, 0.24831113, 0.25047916, 0.25246546],\n",
       "       [0.2400413 , 0.23093966, 0.253831  , 0.27518812],\n",
       "       [0.26768145, 0.23319142, 0.22086854, 0.27825856],\n",
       "       [0.21535334, 0.25637025, 0.28404322, 0.2442331 ],\n",
       "       [0.2504856 , 0.26534134, 0.25707516, 0.22709788],\n",
       "       [0.22595182, 0.23917921, 0.2802362 , 0.2546327 ],\n",
       "       [0.22134694, 0.2519685 , 0.27386478, 0.25281978],\n",
       "       [0.23555507, 0.23473385, 0.27284896, 0.2568621 ],\n",
       "       [0.24753368, 0.251003  , 0.24258685, 0.25887653],\n",
       "       [0.27546614, 0.25091985, 0.22402117, 0.24959284],\n",
       "       [0.28011343, 0.23750882, 0.22134998, 0.26102778],\n",
       "       [0.23060662, 0.2562739 , 0.2644912 , 0.24862824],\n",
       "       [0.24994485, 0.24004957, 0.25740188, 0.25260365],\n",
       "       [0.2029301 , 0.24756667, 0.3048158 , 0.2446874 ],\n",
       "       [0.23250161, 0.27051145, 0.26837987, 0.22860706],\n",
       "       [0.23122603, 0.26115602, 0.26522794, 0.24239002],\n",
       "       [0.23617014, 0.2530557 , 0.26902005, 0.24175416],\n",
       "       [0.22533269, 0.25305584, 0.27311307, 0.24849838],\n",
       "       [0.20383564, 0.24625106, 0.29842788, 0.25148547],\n",
       "       [0.26714346, 0.26411963, 0.24177076, 0.22696617],\n",
       "       [0.23196508, 0.2649521 , 0.2706277 , 0.23245515],\n",
       "       [0.24577476, 0.26113054, 0.25240195, 0.24069281],\n",
       "       [0.2389814 , 0.22293463, 0.2687895 , 0.2692944 ],\n",
       "       [0.2132375 , 0.23209514, 0.29098973, 0.26367763],\n",
       "       [0.2447853 , 0.22388999, 0.25265688, 0.27866778],\n",
       "       [0.2581919 , 0.24861343, 0.22881621, 0.26437846],\n",
       "       [0.20797533, 0.24938256, 0.29947707, 0.243165  ],\n",
       "       [0.26620954, 0.23653966, 0.23479256, 0.26245818],\n",
       "       [0.2508686 , 0.26024786, 0.25195658, 0.23692688],\n",
       "       [0.21577862, 0.2520357 , 0.28656676, 0.24561888],\n",
       "       [0.21148577, 0.24046066, 0.2937456 , 0.25430796],\n",
       "       [0.26744354, 0.263526  , 0.23391268, 0.23511776],\n",
       "       [0.19605303, 0.23176475, 0.30504093, 0.26714128],\n",
       "       [0.22998646, 0.24160334, 0.28131294, 0.24709727],\n",
       "       [0.28375855, 0.23934147, 0.2201236 , 0.25677636],\n",
       "       [0.2544896 , 0.28146595, 0.2453986 , 0.21864586],\n",
       "       [0.25982368, 0.27028894, 0.2409838 , 0.22890355],\n",
       "       [0.22406824, 0.22451188, 0.2775261 , 0.27389377],\n",
       "       [0.26042742, 0.23957454, 0.24924129, 0.2507568 ],\n",
       "       [0.25336146, 0.25122172, 0.2572936 , 0.23812322],\n",
       "       [0.21181735, 0.23752232, 0.29792312, 0.25273725],\n",
       "       [0.22414559, 0.2580633 , 0.27851844, 0.2392727 ],\n",
       "       [0.23258138, 0.26058036, 0.26298675, 0.24385156],\n",
       "       [0.22595207, 0.26069474, 0.27607447, 0.23727873],\n",
       "       [0.2553234 , 0.28083587, 0.24669506, 0.21714565],\n",
       "       [0.22628859, 0.24211787, 0.2738466 , 0.25774696],\n",
       "       [0.25120667, 0.2384426 , 0.24818188, 0.2621689 ],\n",
       "       [0.23068687, 0.26706576, 0.27028853, 0.23195878],\n",
       "       [0.24947238, 0.27908292, 0.2521328 , 0.21931177],\n",
       "       [0.26860237, 0.24269535, 0.23433875, 0.25436354],\n",
       "       [0.23800859, 0.23934193, 0.2674981 , 0.2551514 ],\n",
       "       [0.22061285, 0.24568066, 0.27732804, 0.25637844],\n",
       "       [0.22479685, 0.23928249, 0.26757511, 0.26834553],\n",
       "       [0.2267747 , 0.2648929 , 0.27190584, 0.23642662],\n",
       "       [0.2824509 , 0.23740803, 0.21883033, 0.2613107 ],\n",
       "       [0.1991786 , 0.24359483, 0.30958456, 0.24764198],\n",
       "       [0.23646367, 0.2626138 , 0.2688517 , 0.23207082],\n",
       "       [0.22636083, 0.20634125, 0.27890024, 0.2883977 ],\n",
       "       [0.2551832 , 0.26766172, 0.24223776, 0.2349173 ],\n",
       "       [0.27922517, 0.2668386 , 0.22657077, 0.22736539]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reinforce_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2707125 , 0.2513453 , 0.22590981, 0.2520324 ],\n",
       "       [0.19331466, 0.22725874, 0.31421083, 0.26521572],\n",
       "       [0.24475338, 0.2635193 , 0.25421354, 0.23751374],\n",
       "       [0.2590985 , 0.24802794, 0.23698923, 0.25588438],\n",
       "       [0.20159769, 0.23186167, 0.30598143, 0.2605593 ],\n",
       "       [0.23178771, 0.2537843 , 0.2683345 , 0.24609353],\n",
       "       [0.24947914, 0.24418765, 0.26008546, 0.24624771],\n",
       "       [0.22400893, 0.24987115, 0.27230942, 0.25381052],\n",
       "       [0.24556835, 0.2650649 , 0.25942785, 0.22993891],\n",
       "       [0.27468607, 0.27917215, 0.22837645, 0.21776542],\n",
       "       [0.23816544, 0.23292162, 0.2681064 , 0.26080653],\n",
       "       [0.26135236, 0.2509886 , 0.24235629, 0.24530281],\n",
       "       [0.22897157, 0.23685037, 0.2702013 , 0.2639767 ],\n",
       "       [0.2311213 , 0.26255873, 0.27154806, 0.234772  ],\n",
       "       [0.27146247, 0.23608547, 0.22622305, 0.26622903],\n",
       "       [0.24874417, 0.24831113, 0.25047916, 0.25246546],\n",
       "       [0.2400413 , 0.23093966, 0.253831  , 0.27518812],\n",
       "       [0.26768145, 0.23319142, 0.22086854, 0.27825856],\n",
       "       [0.21535334, 0.25637025, 0.28404322, 0.2442331 ],\n",
       "       [0.2504856 , 0.26534134, 0.25707516, 0.22709788],\n",
       "       [0.22595182, 0.23917921, 0.2802362 , 0.2546327 ],\n",
       "       [0.22134694, 0.2519685 , 0.27386478, 0.25281978],\n",
       "       [0.23555507, 0.23473385, 0.27284896, 0.2568621 ],\n",
       "       [0.24753368, 0.251003  , 0.24258685, 0.25887653],\n",
       "       [0.27546614, 0.25091985, 0.22402117, 0.24959284],\n",
       "       [0.28011343, 0.23750882, 0.22134998, 0.26102778],\n",
       "       [0.23060662, 0.2562739 , 0.2644912 , 0.24862824],\n",
       "       [0.24994485, 0.24004957, 0.25740188, 0.25260365],\n",
       "       [0.2029301 , 0.24756667, 0.3048158 , 0.2446874 ],\n",
       "       [0.23250161, 0.27051145, 0.26837987, 0.22860706],\n",
       "       [0.23122603, 0.26115602, 0.26522794, 0.24239002],\n",
       "       [0.23617014, 0.2530557 , 0.26902005, 0.24175416],\n",
       "       [0.22533269, 0.25305584, 0.27311307, 0.24849838],\n",
       "       [0.20383564, 0.24625106, 0.29842788, 0.25148547],\n",
       "       [0.26714346, 0.26411963, 0.24177076, 0.22696617],\n",
       "       [0.23196508, 0.2649521 , 0.2706277 , 0.23245515],\n",
       "       [0.24577476, 0.26113054, 0.25240195, 0.24069281],\n",
       "       [0.2389814 , 0.22293463, 0.2687895 , 0.2692944 ],\n",
       "       [0.2132375 , 0.23209514, 0.29098973, 0.26367763],\n",
       "       [0.2447853 , 0.22388999, 0.25265688, 0.27866778],\n",
       "       [0.2581919 , 0.24861343, 0.22881621, 0.26437846],\n",
       "       [0.20797533, 0.24938256, 0.29947707, 0.243165  ],\n",
       "       [0.26620954, 0.23653966, 0.23479256, 0.26245818],\n",
       "       [0.2508686 , 0.26024786, 0.25195658, 0.23692688],\n",
       "       [0.21577862, 0.2520357 , 0.28656676, 0.24561888],\n",
       "       [0.21148577, 0.24046066, 0.2937456 , 0.25430796],\n",
       "       [0.26744354, 0.263526  , 0.23391268, 0.23511776],\n",
       "       [0.19605303, 0.23176475, 0.30504093, 0.26714128],\n",
       "       [0.22998646, 0.24160334, 0.28131294, 0.24709727],\n",
       "       [0.28375855, 0.23934147, 0.2201236 , 0.25677636],\n",
       "       [0.2544896 , 0.28146595, 0.2453986 , 0.21864586],\n",
       "       [0.25982368, 0.27028894, 0.2409838 , 0.22890355],\n",
       "       [0.22406824, 0.22451188, 0.2775261 , 0.27389377],\n",
       "       [0.26042742, 0.23957454, 0.24924129, 0.2507568 ],\n",
       "       [0.25336146, 0.25122172, 0.2572936 , 0.23812322],\n",
       "       [0.21181735, 0.23752232, 0.29792312, 0.25273725],\n",
       "       [0.22414559, 0.2580633 , 0.27851844, 0.2392727 ],\n",
       "       [0.23258138, 0.26058036, 0.26298675, 0.24385156],\n",
       "       [0.22595207, 0.26069474, 0.27607447, 0.23727873],\n",
       "       [0.2553234 , 0.28083587, 0.24669506, 0.21714565],\n",
       "       [0.22628859, 0.24211787, 0.2738466 , 0.25774696],\n",
       "       [0.25120667, 0.2384426 , 0.24818188, 0.2621689 ],\n",
       "       [0.23068687, 0.26706576, 0.27028853, 0.23195878],\n",
       "       [0.24947238, 0.27908292, 0.2521328 , 0.21931177],\n",
       "       [0.26860237, 0.24269535, 0.23433875, 0.25436354],\n",
       "       [0.23800859, 0.23934193, 0.2674981 , 0.2551514 ],\n",
       "       [0.22061285, 0.24568066, 0.27732804, 0.25637844],\n",
       "       [0.22479685, 0.23928249, 0.26757511, 0.26834553],\n",
       "       [0.2267747 , 0.2648929 , 0.27190584, 0.23642662],\n",
       "       [0.2824509 , 0.23740803, 0.21883033, 0.2613107 ],\n",
       "       [0.1991786 , 0.24359483, 0.30958456, 0.24764198],\n",
       "       [0.23646367, 0.2626138 , 0.2688517 , 0.23207082],\n",
       "       [0.22636083, 0.20634125, 0.27890024, 0.2883977 ],\n",
       "       [0.2551832 , 0.26766172, 0.24223776, 0.2349173 ],\n",
       "       [0.27922517, 0.2668386 , 0.22657077, 0.22736539]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reinforce_model.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When using data tensors as input to a model, you should specify the `steps` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5a26e3405088>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpolicy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'next_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/HungryGeese/agents/nnAgent.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bias_initializer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mperf_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m     return func.predict(\n\u001b[0m\u001b[1;32m    983\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m               **kwargs):\n\u001b[1;32m    703\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m     x, _, _ = model._standardize_user_data(\n\u001b[0m\u001b[1;32m    705\u001b[0m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[1;32m    706\u001b[0m     return predict_loop(\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2293\u001b[0m     \u001b[0;31m# Validates `steps` argument based on x's type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2295\u001b[0;31m       \u001b[0mtraining_utils_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_steps_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_utils_v1.py\u001b[0m in \u001b[0;36mcheck_steps_argument\u001b[0;34m(input_data, steps, steps_name)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m       \u001b[0minput_type_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a Dataset iterator'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_x_iterator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'data tensors'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m       raise ValueError('When using {input_type} as input to a model, you should'\n\u001b[0m\u001b[1;32m   1203\u001b[0m                        ' specify the `{steps_name}` argument.'.format(\n\u001b[1;32m   1204\u001b[0m                            input_type=input_type_str, steps_name=steps_name))\n",
      "\u001b[0;31mValueError\u001b[0m: When using data tensors as input to a model, you should specify the `steps` argument."
     ]
    }
   ],
   "source": [
    "policy_model.predict(data['next_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor Tensor(\"dense_5/Softmax:0\", shape=(None, 4), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-b68daeccd48c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreinforce_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/HungryGeese/agents/nnAgent.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bias_initializer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mperf_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m     return func.predict(\n\u001b[0m\u001b[1;32m    983\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    704\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[1;32m    705\u001b[0m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0;32m--> 706\u001b[0;31m     return predict_loop(\n\u001b[0m\u001b[1;32m    707\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m   \u001b[0;31m# function we recompile the metrics based on the updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0;31m# sample_weight_mode value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m   \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[0;31m# Prepare validation data. Hold references to the iterator and the input list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[0;34m(model, mode)\u001b[0m\n\u001b[1;32m    553\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistributed_training_utils_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2082\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_make_predict_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2067\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_function_kwargs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m         self.predict_function = K.function(\n\u001b[0m\u001b[1;32m   2070\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[1;32m   4084\u001b[0m                'backend') % key\n\u001b[1;32m   4085\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4086\u001b[0;31m   return GraphExecutionFunction(\n\u001b[0m\u001b[1;32m   4087\u001b[0m       inputs, outputs, updates=updates, name=name, **kwargs)\n\u001b[1;32m   4088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, updates, name, **session_kwargs)\u001b[0m\n\u001b[1;32m   3808\u001b[0m     \u001b[0;31m# dependencies in call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m     \u001b[0;31m# Index 0 = total loss or model output for `predict`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3810\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3811\u001b[0m       \u001b[0mupdates_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(control_inputs)\u001b[0m\n\u001b[1;32m   5357\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mNullContextmanager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5358\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5359\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[0;34m(self, control_inputs)\u001b[0m\n\u001b[1;32m   4813\u001b[0m           (hasattr(c, \"_handle\") and hasattr(c, \"op\"))):\n\u001b[1;32m   4814\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4815\u001b[0;31m       \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4816\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4817\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3725\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3726\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3728\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HungryGeese/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3803\u001b[0m       \u001b[0;31m# Actually obj is just the object it's referring to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3804\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOperation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"dense_5/Softmax:0\", shape=(None, 4), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "reinforce_model.predict(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(shape=X_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7302, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Copy weights from rule_based model to reinforce model\n",
    "2. set 2 versions of v_model\n",
    "3. loop:\n",
    "    Run simulations\n",
    "    get training data\n",
    "    add advantage estimate\n",
    "    train reinforce model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7f45ec7f9130>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_model.load('state_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_advantage(data, model):\n",
    "    cur_state_val = v_model.predict(data['state'])\n",
    "    next_state_val = np.array(data['reward']).reshape(-1, 1) + 0.85*v_model.predict(data['next_state'])*(np.array(data['done']) == False)\n",
    "    return (next_state_val - cur_state_val).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.670556],\n",
       "       [ 6.670519],\n",
       "       [ 6.67069 ],\n",
       "       ...,\n",
       "       [ 9.093634],\n",
       "       [ 9.553383],\n",
       "       [10.162241]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_state_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_v = v_model.predict(data['next_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array(data['reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.670519 ],\n",
       "       [ 6.67069  ],\n",
       "       [ 6.6710367],\n",
       "       ...,\n",
       "       [ 9.553383 ],\n",
       "       [10.162241 ],\n",
       "       [10.162241 ]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.66994143,  6.66994143,  6.66994143, ...,  6.66994143,\n",
       "         6.66994143, 10.        ],\n",
       "       [ 6.67008686,  6.67008686,  6.67008686, ...,  6.67008686,\n",
       "         6.67008686, 10.        ],\n",
       "       [ 6.67038155,  6.67038155,  6.67038155, ...,  6.67038155,\n",
       "         6.67038155, 10.        ],\n",
       "       ...,\n",
       "       [ 9.12037563,  9.12037563,  9.12037563, ...,  9.12037563,\n",
       "         9.12037563, 10.        ],\n",
       "       [ 9.63790512,  9.63790512,  9.63790512, ...,  9.63790512,\n",
       "         9.63790512, 10.        ],\n",
       "       [ 9.63790512,  9.63790512,  9.63790512, ...,  9.63790512,\n",
       "         9.63790512, 10.        ]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage = compute_advantage(data, v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.14643097e-04],\n",
       "       [-6.14643097e-04],\n",
       "       [-6.14643097e-04],\n",
       "       ...,\n",
       "       [ 8.47566414e+00],\n",
       "       [ 8.47566414e+00],\n",
       "       [-1.62240982e-01]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1785657269978007"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(advantage>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_state_value(discount, steps):\n",
    "    steps_back = steps[::-1]\n",
    "    v_prime = 0\n",
    "    for step in steps_back:\n",
    "        v = step['reward'] + discount*v_prime\n",
    "        v_prime = v\n",
    "        step['v'] = v\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.666549330923931"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+0.85*6.666528624616389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9520000000000004"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 0.8* (1+ 0.8* (1+ 0.8*(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(10).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1487, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['state'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reward'][1485]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.670556],\n",
       "       [ 6.670519],\n",
       "       [ 6.67069 ],\n",
       "       ...,\n",
       "       [ 9.093634],\n",
       "       [ 9.553383],\n",
       "       [10.162241]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_model.predict(data['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08452184999999979"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+0.85*10.162241 - 9.553383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.670519 ],\n",
       "       [ 6.67069  ],\n",
       "       [ 6.6710367],\n",
       "       ...,\n",
       "       [ 9.553383 ],\n",
       "       [10.162241 ],\n",
       "       [10.162241 ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_model.predict(data['next_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33414078],\n",
       "       [-0.33414078],\n",
       "       [-0.33414078],\n",
       "       ...,\n",
       "       [-1.03244781],\n",
       "       [-1.03244781],\n",
       "       [-0.16224098]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -10,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 16.666655795888097,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -30,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -10,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -30,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -10,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.670519 ],\n",
       "       [ 6.67069  ],\n",
       "       [ 6.6710367],\n",
       "       ...,\n",
       "       [ 9.553383 ],\n",
       "       [10.162241 ],\n",
       "       [10.162241 ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_model.predict(data['next_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
